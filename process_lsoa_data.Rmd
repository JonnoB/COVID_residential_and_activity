---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

This file is designed to do the Loading and processing of the data to be used in this project

The file is broken into 3 parts the setup which defines all the packages used and file paths, The residential features,
the activity features.


#  Setup


```{r}

packages <- c("readxl", "readr", "tidyverse", "lubridate", "ggcorrplot")

new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

sapply(packages, library, character.only = TRUE)

library(ukcovid19)

base_folder <- file.path("/home/jonno", "COVID_project")
data_folder <- file.path(base_folder, "COVID_project_data")

list.files(data_folder)
```

#Covid data

This uses the ukcovid19 package by public health england to get the historical data

```{r}
# query_filters <- c(
#     'areaType=ltla'
# )
# 
# cases_and_deaths = list(
#  #   date = "date"#,
#   #  areaName = "areaName",
#   #  ltlaName = "LtlaName",
#  #   areaCode = "areaCode",
#   #  areaType = "areaType",
#     cumVaccinationFirstDoseUptakeByVaccinationDatePercentage = "cumVaccinationFirstDoseUptakeByVaccinationDatePercentage"
# )
# 
# data <- get_data(
#     filters = query_filters, 
#     structure = cases_and_deaths
# )

#there is a lot of missing data, I am not totally sure if this is because 0/less than 3, is not reported
{
covid_msoa_time <- read_csv(file.path(data_folder, "covid_uk_msoa_07202021.csv")) %>%
  select(-X1) %>%
  arrange(date) %>%
  rename(rolling_sum = newCasesBySpecimenDateRollingSum ) %>%
  group_by(areaCode) %>%
  mutate(current_cases =lag(rolling_sum) ) %>%
  ungroup %>%
  filter(date> ymd("2020-05-01"))

covid_msoa_time <- expand_grid(date = unique(covid_msoa_time$date), areaCode = unique(covid_msoa_time$areaCode)) %>%
  left_join(covid_msoa_time) %>%
  mutate(rolling_sum = ifelse(is.na(rolling_sum), 0, rolling_sum)) %>%
  group_by(date) %>%
  mutate(diff = rolling_sum-mean(rolling_sum)) %>%
  ungroup
}




covid_msoa_time %>%
  ggplot(aes(x = date, y = diff, group = areaCode)) + geom_line(alpha =0.05) +
  scale_y_log10()

unique(covid_msoa_time$areaCode)




cor_mat <-covid_msoa_time %>%
select(areaCode, date, target_var) %>%
  pivot_wider(., values_from = target_var, names_from = areaCode) %>%
  select(-date) %>%
  cor(., use = "pairwise.complete.obs", method = "kendall")


test <- as_tibble(cor_mat) %>% mutate(name1 = rownames(cor_mat)) %>% 
  pivot_longer(cols = -name1, names_to = "name2") %>%
  filter(name1!=name2) %>%
  mutate(percentile = percent_rank(value))

#95% of values fall between 0.43 and 0.784
test %>%
  filter(percentile>0.025 & percentile<0.975) %>%
  arrange(value) %>%
  slice(1, n())

test %>%
  filter(name1!=name2) %>%
  ggplot(aes(x = value)) + geom_density()

ggcorrplot(cor_mat, hc.order = TRUE)


```


#lsoa msoa lookup

```{r}
geog_lookup <- read_csv(file.path(data_folder, "Output_Area_to_LSOA_to_MSOA_to_Local_Authority_District_(December_2017)_Lookup_with_Area_Classifications_in_Great_Britain.csv")) %>%
  filter(RGN11NM == "London") %>%
  rename(msoa.code = MSOA11CD,
         lsoa.code = LSOA11CD)

msoa_class <- geog_lookup %>%
  group_by(SOAC11CD, SOAC11NM, msoa.code) %>%
  summarise(counts = n()) %>%
  group_by(msoa.code) %>%
  mutate(fract = counts/sum(counts)) %>%
  arrange(-fract) %>%
  slice(1) %>%
  ungroup %>%
  mutate(class2 = ifelse(fract<.5, "mixed type", SOAC11NM))

```



#Residential features

##Age

This chunk get the age of the residents of an LSOA, breaking them into above and below 60. The data comes from the ONS and is called "Lower layer Super Output Area population estimates (supporting information)" it can be found at https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/lowersuperoutputareamidyearpopulationestimates

NOTE: this data includes only England and Wales

```{r}


#load data and make lower case headings with spaces as periods
raw_data <- read_excel(file.path(path = data_folder,"SAPE22DT2-mid-2019-lsoa-syoa-estimates-unformatted.xlsx"), 
                   sheet = "Mid-2019 Persons",
                   skip = 3,
                   .name_repair = "universal")  %>%
  set_names(., nm = tolower(names(.)))


#which lsoa standard are we going to use? 2011 or 2019?
#this code currently uses 2011

age_df <- raw_data %>%
  rowwise(lsoa.code) %>%
    #first select the rows that are numbers, then sum them row wise
  mutate(younger =  c_across(num_range(prefix = "...", range = 0:59)) %>% sum(),
         older =  c_across(c(num_range(prefix = "...", range = 90:100), "..90.")) %>% sum()) %>%
  ungroup %>%
  select(lsoa.code, younger, older) %>%
  mutate(total = younger+older,
         fract_older = older/total)
  

```


##Air pollution

This data set comes from  "Access to Healthy Assets & Hazards (AHAH)" produced by the CDRC, available at https://data.cdrc.ac.uk/dataset/access-healthy-assets-hazards-ahah

There are two different datasets available, one represents the indecies whilt the other the input data. I have for now chosen to use input data and take only PM10 as the airquality indicator. This can be changed

meta data describing the headers is also available from the same place.


```{r}

air_pollution_df <- read_csv(file.path(data_folder, "allvariableslsoawdeciles.csv"  )) %>%
  select(lsoa11, pm10_mean)

#The index files
#test <- read_csv(file.path(data_folder, "ahahv2domainsindex.csv"))
```


##Deprivation

The deprivation data comes from the ONS and is available from https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019

lower scores are MORE deprived, higher scores are LESS deprived

NOTE: this data includes only England

```{r}
deprivation_df <- read_excel(file.path(data_folder, "File_1_-_IMD2019_Index_of_Multiple_Deprivation.xlsx"),  
                             sheet = "IMD2019",
                   .name_repair = "universal")  %>%
  set_names(., nm = tolower(names(.))) %>%
  select(lsoa.code = "lsoa.code..2011.", imd_rank = "index.of.multiple.deprivation..imd..rank")


```


##Ethnicity

I have applied for access to the CDRC ethnicity estimates dataset. Information on this dataset can be found here https://data.cdrc.ac.uk/dataset/cdrc-modelled-ethnicity-proportions-lsoa-geography

This dataset is more upto date than the census and includes a somewhat reduced number of ethnicities than the census. 

```{r}

```



##Merge datasets

This chunk simply merges the different datasets to produce a single dataset of very limited number of variables to use as the residential LSOA features.


The resulting dataset includes only complete cases, as such it is only the data for England.

```{r}

#aggregate to msoa level using population weighted means
residential_msoa_df <- age_df %>%
  select(lsoa.code, fract_older, pop = total) %>%
  left_join(., air_pollution_df, by = c("lsoa.code" ="lsoa11") ) %>%
  left_join(., deprivation_df, by = c("lsoa.code" )) %>%
  filter(complete.cases(.))%>%
  left_join(  geog_lookup %>%
  select(lsoa.code, msoa.code) %>%
    distinct()) %>%
  filter(!is.na(msoa.code)) %>%
  select(-lsoa.code) %>%
  group_by(msoa.code) %>%
  summarise(fract_older = weighted.mean(fract_older, w = pop),
            pm10_mean = weighted.mean(pm10_mean, w = pop),
            imd_rank = weighted.mean(imd_rank, w = pop))


write_csv(residential_msoa_df, file = file.path(data_folder, "msoa_demographics.csv"))
```


#Activity features

This section loads the data that will be used as the activity or functional features of the data set to determin what sort of activities are taking place when they are the destination of someone travelling there from there home LSOA.

Although we have discussed using the method created by the Cambridge team the CDRC have made produced a freely available dataset for the entire country that has a substantial amount of useful information in it. Due to it's availablibity this may be a better starting point than trying to re-create the Doc2Vec method.

The CRDC dataset is called "Classification of Multidimensional Open Data of Urban Morphology (MODUM)" and is available from "https://data.cdrc.ac.uk/dataset/classification-multidimensional-open-data-urban-morphology-modum".

The data is at OA level and so would need to be aggregated to LSOA level. However, depending on the granularity of the data we get from Alexi we could also use it at OA level.



```{r}

```

